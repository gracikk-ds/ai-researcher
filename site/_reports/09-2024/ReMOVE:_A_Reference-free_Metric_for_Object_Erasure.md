---
title: ReMOVE:_A_Reference-free_Metric_for_Object_Erasure
layout: default
date: 2024-09-01
---
## ReMOVE: A Reference-free Metric for Object Erasure
**Authors:**
- Aditya Chandrasekar, h-index: 2, papers: 2, citations: 11
- Prathosh AP

**ArXiv URL:** http://arxiv.org/abs/2409.00707v1

**Citation Count:** None

**Published Date:** 2024-09-01

![Figure 1. Motivation for ReMOVE : Comparison of ReMOVE with CLIPScore, illustrating the latter’s lack of distinction (denoted by ✓ and ✗ ) between two inpainting methods: method]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
The authors address the challenge of evaluating object erasure in diffusion-based image editing models. Existing metrics are often inadequate for this task. Reference-based metrics like LPIPS require a ground-truth image (the scene without the object), which is typically unavailable in real-world applications. On the other hand, reference-free metrics like CLIPScore often fail to distinguish between successful object removal (where the background is plausibly filled in) and unintended object replacement (where the model inserts a new, different object), a common failure mode for diffusion models. This creates a gap for a reliable, reference-free metric specifically designed for the object erasure task.

## 2. Key Ideas and Methodology
The core idea behind ReMOVE is that a successfully inpainted region should be semantically and texturally indistinguishable from its surrounding background. The metric quantifies this consistency using deep features.

The methodology is as follows:
1.  An edited image and its corresponding object mask are taken as input.
2.  The image is passed through a pre-trained Vision Transformer (ViT) to extract patch-level feature embeddings. The ViT was originally trained for image segmentation, enabling it to capture rich, localized semantic information.
3.  Using the mask, the patch embeddings are divided into two sets: those from the inpainted (masked) region and those from the surrounding background (unmasked) region.
4.  The mean feature vector is calculated for each set.
5.  The final ReMOVE score is the cosine similarity between the mean feature vector of the inpainted region and the mean feature vector of the background. A higher score indicates greater similarity and thus a more successful object erasure.

## 3. Datasets Used / Presented
The authors use two datasets to validate their metric:

1.  **Toy Dataset:** A synthetic dataset created by the authors for controlled validation. It consists of ~200,000 images generated by applying Stable Diffusion Inpaint to 4,300 background landscape images using 20 different masks from the PIE-Bench dataset. The original background images serve as ground truth. This dataset was used to establish a baseline correlation between ReMOVE and the reference-based metric LPIPS.

2.  **DEFACTO Dataset:** A real-world dataset for object removal, constructed over MSCOCO. It contains ~25,000 tuples of an input image, an inpainting mask, and a ground-truth inpainted image. This dataset features more complex scenes and a wide variation in mask sizes, and was used to test ReMOVE's performance in a realistic scenario against both LPIPS and CLIPScore.

## 4. Main Results
ReMOVE demonstrates a strong correlation with established metrics and human perception, outperforming existing reference-free alternatives for the object erasure task.

-   On both the Toy and DEFACTO datasets, ReMOVE showed a consistent negative correlation with LPIPS (correlation coefficient ρ ≈ -0.52), meaning as LPIPS scores improved (got lower), ReMOVE scores also improved (got higher), as expected.
-   In experiments on the DEFACTO dataset, both reference-free and full-reference versions of CLIPScore produced noisy and unreliable predictions, whereas ReMOVE's trend closely followed that of LPIPS.
-   In a user study involving 1000 pairwise comparisons, ReMOVE's assessment of inpainting quality aligned with human preference 74.7% of the time, which was more frequent than the reference-based LPIPS metric (71.9%).

The authors conclude that ReMOVE is a valuable and reliable reference-free tool for evaluating object erasure, capturing nuances that other metrics miss.

## 5. Ablation Studies
The paper reports a key ablation study on the necessity of a cropping preprocessing step. This step crops the image around the mask to ensure the masked and unmasked regions have a comparable number of patches, which is particularly important for small masks.

-   **Experiment:** The performance of ReMOVE with cropping was compared to its performance without cropping on both the Toy and DEFACTO datasets.
-   **Impact:** On the DEFACTO dataset, which has highly variable mask sizes, cropping was critical. Without cropping, ReMOVE produced implausible results with a poor correlation to LPIPS (ρ = +0.145). With cropping, the correlation became strong and correct (ρ = -0.515). This demonstrates that the cropping strategy is essential for the metric's reliability on real-world data.

## 6. Paper Figures
![Figure 2. Randomness in Object Inpainting using SD-Inpaint : Samples of diffusion-based image inpainting using SD-Inpaint [ 31 ] generated across varying seeds. The object intended for inpainting is substituted with a different object rather than replacing it with the background. In some cases (column 6), the model replaces the object with background pixels as desired.]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_2.jpg' | relative_url }})
![Figure 3. Randomness in Object Inpainting with Other Methods : Samples of diffusion-based image inpainting using multiple methods. The object intended for inpainting is often substituted with a different object rather than replacing it with the background.]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_3.jpg' | relative_url }})
![Figure 4. Schematic Diagram of ReMOVE : The inpainter]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_4.jpg' | relative_url }})
![Figure 5. Toy Dataset made using background images, randomly selected masks and SD-Inpaint.]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_5.jpg' | relative_url }})
![Figure 7. Samples from the object removal category of DEFACTO dataset.]({{ '/images/09-2024/ReMOVE:_A_Reference-free_Metric_for_Object_Erasure/figure_7.jpg' | relative_url }})
