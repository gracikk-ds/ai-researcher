---
title: OmniEdit:_Building_Image_Editing_Generalist_Models_Through_Specialist_Supervision
layout: default
date: 2024-11-11
---
![Figure 1: Editing high-resolution multi-aspect images with O MNI -E DIT . O MNI -E DIT is an instruction-based image editing generalist capable of performing diverse editing tasks across different aspect ratios and resolutions. It accurately follows instructions while preserving the original image’s fidelity. We suggest zooming in for better visualization.]({{ '/images/11-2024/OmniEdit:_Building_Image_Editing_Generalist_Models_Through_Specialist_Supervision/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
Instruction-guided image editing models often fail in real-world applications due to three primary challenges. First, they possess limited and imbalanced editing skills because they are trained on datasets generated by biased synthesis methods (e.g., some methods excel at local edits but fail at global ones, and vice-versa). Second, the training data suffers from poor quality, as it is typically filtered using simple, unreliable metrics like CLIP-score. Third, existing models lack versatility, as they are almost exclusively trained on low-resolution, square images, making them perform poorly on images with diverse aspect ratios and resolutions.

## 2. Key Ideas and Methodology
The paper introduces OMNI-EDIT, a generalist image editing model trained using a "specialist-to-generalist" supervision framework. The core idea is to leverage the strengths of multiple specialized models to teach a single, powerful generalist model.

The methodology consists of a four-stage pipeline:
1.  **Specialist Learning:** Seven specialist models are constructed or trained, each excelling at a specific editing task (e.g., object removal, style transfer, attribute modification).
2.  **Synthetic Data Generation:** These specialists are used to generate a large, diverse dataset of over 5 million image editing pairs, covering high resolutions and multiple aspect ratios.
3.  **Importance Sampling:** To ensure data quality, a Large Multimodal Model (LMM), specifically GPT-4o distilled into the smaller InternVL2 model, is used to score and filter the generated pairs. This acts as a high-quality importance weighting function, retaining only the most accurate and artifact-free examples.
4.  **Generalist Training:** The final OMNI-EDIT model is trained on this curated, high-quality dataset. It uses a novel **EditNet** architecture, which adapts a pre-trained diffusion transformer (SD3) by adding a trainable control branch. Unlike ControlNet, EditNet allows for interaction between the intermediate representations of the control and main branches and updates text representations, enabling a better understanding of complex instructions.

## 3. Datasets Used / Presented
*   **OMNI-EDIT Training Dataset:** A large-scale training set created by the authors. It consists of **1.2 million** high-quality image-instruction pairs, filtered down from an initial set of 5.2 million. The images are sourced from LAION-5B and OpenImageV6, featuring high resolutions (>1 megapixel) and six different aspect ratios.
*   **OMNI-EDIT-Bench:** A new benchmark created for evaluation. It contains 62 high-resolution, multi-aspect-ratio images, with 7 different editing instructions applied to each, resulting in a total of **434** test cases that cover a wide range of editing tasks.

## 4. Main Results
OMNI-EDIT significantly outperforms existing state-of-the-art models across both automated (VIEScore) and human evaluations.
*   In human evaluations on the OMNI-EDIT-Bench, OMNI-EDIT achieved an overall quality score of **0.69** and an instruction-following accuracy of **55%**. This was a substantial improvement over the best-performing baseline, CosXL-Edit, which scored 0.59 and 35%, respectively.
*   Qualitative results show OMNI-EDIT produces higher-fidelity edits, better preserves background content, and successfully handles diverse tasks on non-square, high-resolution images where other models often fail or produce blurry results.
*   The author-claimed impact is that the specialist-to-generalist framework with LMM-based quality control is a highly effective approach for building versatile and robust image editing models.

## 5. Ablation Studies
*   **Importance Sampling:** The authors trained a version of OMNI-EDIT without the LMM-based data filtering step. This resulted in a drastic drop in performance, with the VIEScore (GPT-4o) Overall score falling from **6.98 to 3.30**. This confirms that high-quality data filtering is critical to the model's success.
*   **Architecture Design:** OMNI-EDIT's EditNet architecture was compared against two ControlNet-based variants trained on the same data. EditNet significantly outperformed both, achieving a VIEScore Overall score of **6.98**, compared to **4.89** and **4.75** for the ControlNet variants. This demonstrates that EditNet's design, particularly the intermediate representation interaction, is superior for understanding complex editing instructions like object removal.

## 6. Paper Figures
![Figure 2: Overview of the O MNI -E DIT training pipeline. The pipeline consists of four stages: (1) task-specific specialist models are trained for diverse editing tasks; (2) these specialist models are used to generate a large, high-resolution, multi-aspect-ratio dataset; (3) a cost-efficient distilled large multi-modal model (LMM) assigns importance weights to each pair of image-editing data; and (4) the final generalist model is trained on the weighted dataset.]({{ '/images/11-2024/OmniEdit:_Building_Image_Editing_Generalist_Models_Through_Specialist_Supervision/figure_2.jpg' | relative_url }})
![Figure 3: InternVL2 as a scoring function before (top right) and after (bottom right) fine-tuning on GPT-4o’s response. On the top right, the original InternVL2 fails to identify the unusual distortions in the edited image it also does not spot the error when the edited image fails to meet the specified editing instructions. On the bottom right, finetuned-InternVL2 successfully detects such failures and serve as a reliable scoring function.]({{ '/images/11-2024/OmniEdit:_Building_Image_Editing_Generalist_Models_Through_Specialist_Supervision/figure_3.jpg' | relative_url }})
![Figure 5: Qualitative comparison between baselines and O MNI -E DIT on a subset of the test set.]({{ '/images/11-2024/OmniEdit:_Building_Image_Editing_Generalist_Models_Through_Specialist_Supervision/figure_5.jpg' | relative_url }})
