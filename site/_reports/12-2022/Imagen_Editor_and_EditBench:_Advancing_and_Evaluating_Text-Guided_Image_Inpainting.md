---
title: Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting
layout: default
date: 2022-12-13
---
## Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting
**Authors:**
- Su Wang
- William Chan

**ArXiv URL:** http://arxiv.org/abs/2212.06909v2

**Citation Count:** 188

**Published Date:** 2022-12-13

![Figure 1. A sequence of edits by Imagen Editor . Given an image , a user deﬁned mask , and a text prompt , Imagen Editor makes localized edits to the designated areas. The model meaningfully incorporates the user’s intent and performs photorealistic edits.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
The authors address two key challenges in text-guided image inpainting. First, existing models often struggle with text-image alignment, failing to generate edits that are faithful to the user's text prompt. This is partly because standard training with random masks allows the model to plausibly fill in regions using only the surrounding image context, thereby learning to ignore the text. Second, there is a lack of a systematic and comprehensive benchmark to evaluate the capabilities and limitations of inpainting models across diverse editing scenarios.

## 2. Key Ideas and Methodology
The paper introduces two main contributions: a new model, Imagen Editor, and a new evaluation benchmark, EditBench.

-   **Imagen Editor**: This is a high-resolution (1024x1024) cascaded diffusion model, fine-tuned from Imagen. To enable high-fidelity editing, it introduces new parameterized convolutional encoders to condition each stage of the diffusion process on the full-resolution input image and mask, which was found to be critical for avoiding artifacts.
-   **Object Masking Policy**: The core methodological innovation is a training strategy designed to improve text-image alignment. Instead of using purely random masks, the authors use an off-the-shelf object detector to propose masks that cover entire objects in training images. The hypothesis is that by masking out whole objects, the model is forced to rely more heavily on the text prompt to reconstruct the content, leading to better alignment.

## 3. Datasets Used / Presented
The paper introduces **EditBench**, a new benchmark dataset for evaluating text-guided image inpainting.

-   **Name**: EditBench
-   **Size**: 240 images.
-   **Domain**: It contains a balanced mix of natural images (from Visual Genome and Open Images) and synthetic images (generated by Imagen and Parti).
-   **Usage**: It is used for evaluation. Each image is paired with a manually annotated mask and three types of text prompts (Mask-Simple, Mask-Rich, and Full) designed to probe model capabilities in rendering objects, attributes (color, shape, count), and complex scenes.

## 4. Main Results
Human evaluations on EditBench show that Imagen Editor significantly outperforms contemporary models.

-   In side-by-side comparisons on text-image alignment, human evaluators preferred Imagen Editor over Stable Diffusion v1.5 (78% of the time), DALL-E 2 (77%), and its randomly-masked counterpart (68%).
-   The authors found that, as a cohort, these models are better at rendering objects than text and handle material/color/size attributes more effectively than count/shape attributes.
-   Among automated metrics, text-to-image (T2I) CLIPScore showed the highest correlation with human judgments for selecting the best image from a pair (68-76% agreement).

The authors' main takeaway is that their proposed object-masking strategy leads to across-the-board improvements in text-image alignment, making the model more controllable and faithful to user intent.

## 5. Ablation Studies
The primary ablation study compares **Imagen Editor (IM)**, trained with the proposed object-masking policy, against **Imagen Editor_RM (IM_RM)**, an identical model trained with a conventional random-masking policy.

-   **Experiment**: A side-by-side human evaluation was conducted where annotators chose which model's output better aligned with the text prompt.
-   **Result**: The object-masked model (IM) was preferred in 68% of comparisons against the randomly-masked model (IM_RM). This demonstrates a substantial improvement in text-image alignment. Qualitatively, the object-masked model is shown to be more robust in handling prompts with multiple, fine-grained attribute specifications.

## 6. Paper Figures
![Figure 10. Single-image human evaluations on EditBench MaskSimple by attribute type . Object masking improves adherence to prompt attributes across-the-board (IM vs. IM RM ).]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_10.jpg' | relative_url }})
![Figure 2. Imagenator is an image editing model built by ﬁnetuning Imagen. All of the diffusion models, i.e., the base model and super-resolution (SR) models, condition on high-resolution 1024 × 1024 image and mask inputs. To this end, new convolutional image encoders are introduced.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_2.jpg' | relative_url }})
![Figure 3. Random masks (left) frequently capture background or intersect object boundaries, deﬁning regions that can be plausibly inpainted just from image context alone. Object masks (right) are harder to inpaint from image context alone, encouraging models to rely more on text inputs during training. (Note: This example image was generated by Imagen and is not in the training data.)]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_3.jpg' | relative_url }})
![Figure 4. EditBench example . The full image is used as a reference for successful inpainting. The mask covers the target object with a free-form, non-hinting shape. The three descriptions types are: single-attribute description of the masked object ( MaskSimple ), multi-attribute description of the masked object ( MaskRich ), or whole image ( Full ). Mask-Rich especially probes models’ ability to handle complex attribute binding and inclusion [ 12 ].]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_4.jpg' | relative_url }})
![Figure 5. EditBench encompasses a wide variety of mask sizes, including large masks that contact the edges of the images (which can amount to an uncropping task in some cases).]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_5.jpg' | relative_url }})
![Figure 6. Human evaluation for single model text-image alignment. Full elicits annotators’ overall impression of text-image alignment; Mask-Simple and Mask-Rich check for the correct inclusion of particular attributes and objects, and attribute binding.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_6.jpg' | relative_url }})
![Figure 7. Single-image human evaluations of text-guided image inpainting on EditBench by prompt type . In this ﬁgure, for Mask-Simple and Mask-Rich prompts, text-image alignment is only counted as correct if the edited image correctly includes every attribute and object speciﬁed in the prompt, including the correct attribute binding (setting a very high bar for correctness). Note that due to different evaluation designs, Full vs Mask-only prompts results are less directly comparable.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_7.jpg' | relative_url }})
![Figure 8. Side-by-side human evaluation of image realism & textimage alignment on EditBench Mask-Rich prompts. For textimage alignment, Imagen Editor is preferred in all comparisons.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_8.jpg' | relative_url }})
![Figure 9. Single-image human evaluations on EditBench MaskSimple by object type . As a cohort, models are better at objectrendering than text-rendering.]({{ '/images/12-2022/Imagen_Editor_and_EditBench:_Advancing_and_Evaluating_Text-Guided_Image_Inpainting/figure_9.jpg' | relative_url }})
