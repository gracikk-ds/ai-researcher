---
title: Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes
layout: default
date: 2025-04-14
---
## Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes
**Authors:**
- Huijie Liu
- Guoliang Kangpapers: 1, 

**ArXiv URL:** http://arxiv.org/abs/2504.09948v3

**Citation Count:** None

**Published Date:** 2025-04-14

![Figure 1: Samples demonstrate the superiority of Omni-Dish in generating and editing Chinese culinary dishes. Rows 1-2 show the faithful generation results from Omni-Dish. Row 3 shows the dish editing capabilities. The project homepage is available at https://liuhuijie6410.github.io/OmniDish/ .]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
The authors address the challenge that general-purpose text-to-image models struggle to generate photorealistic and faithful images for specialized domains, particularly for culturally specific subjects like Chinese dishes. These models often fail to recognize specific dish names, misinterpret ingredients, and cannot render the nuanced textures and compositions accurately. This gap limits their practical application in industries like e-commerce and food digitization, where high-quality, culturally authentic imagery is crucial.

## 2. Key Ideas and Methodology
The paper introduces **Omni-Dish**, a text-to-image generation and editing model specifically tailored for Chinese cuisine.

-   **Core Idea:** The central hypothesis is that a model trained on a meticulously curated, large-scale, domain-specific dataset, combined with a sophisticated captioning and training strategy, can significantly outperform general models in both fidelity and photorealism for that domain.
-   **Methodology:**
    1.  **Data Curation Pipeline:** The authors developed a comprehensive pipeline to process 100 million raw image-text pairs. This involves using Vision Language Models (VLLMs) and Large Language Models (LLMs) for filtering (removing text, watermarks), correcting noisy dish names (validated with a custom "DishSim" metric), and adding multi-dimensional tags (e.g., aesthetics, tableware, background).
    2.  **Faithful-Enhanced Training:** A "coarse-to-fine" training strategy is employed. The model first learns basic dish concepts from names and tags. It is then trained on highly detailed descriptions generated by a novel **Two-Stage Recaption Strategy**, where an LLM first describes the dish, and a VLLM then recaptions the image using this description as a prior to capture fine-grained details.
    3.  **Instruction-Based Editing:** To enable editing, the authors propose **Concept-Enhanced P2P**. Instead of directly using Prompt-to-Prompt (P2P) to create training pairs, they first fine-tune the generation model on the target concept (e.g., "steam") to improve its understanding. P2P is then applied to this enhanced model to generate higher-quality and more consistent source-target image pairs for training a dedicated editing model.

## 3. Datasets Used / Presented
-   **Omni-Dish Training Dataset:** A large-scale dataset created by curating 100 million raw dish name-image pairs from China's largest catering website. The final curated dataset is used for training the generation model.
-   **Dish Editing Dataset:** The first open-source dataset for Chinese dish editing, constructed using the authors' Concept-Enhanced P2P method, inpainting, and manual filtering. It is used to train the editing model.
-   **FID-22K:** A custom evaluation dataset of 22,000 high-quality, manually selected dish images used to calculate the Fréchet Inception Distance (FID) for benchmarking generation quality.
-   **Human Evaluation Set:** A set of 3,000 images generated by Omni-Dish and baseline models, used for comprehensive human evaluation across multiple quality dimensions.

## 4. Main Results
-   **Text-to-Dish Generation:** In comparisons against four other Chinese-capable models, Omni-Dish achieved state-of-the-art performance. It obtained the best (lowest) FID score of 14.96 and the highest score on the custom DishSim metric (0.7004), indicating superior image quality and text-image alignment. Human evaluations also ranked Omni-Dish highest in fidelity, texture, composition, and subject completeness.
-   **Dish Editing:** The Omni-Dish based editing model significantly outperformed existing methods like IP2P and MagicBrush. In human evaluations, it scored highest on editing effectiveness (2.83 out of 3) and aesthetics (2.44 out of 3), demonstrating its ability to follow complex instructions accurately while maintaining high visual quality.
-   **Author's Takeaway:** The authors successfully demonstrate that a specialized data curation pipeline and a tailored training strategy can create a foundation model that excels at generating and editing culturally nuanced and highly detailed images, overcoming the limitations of general-purpose models.

## 5. Ablation Studies
-   **Effect of Recaption Strategy:** The paper validates the impact of using detailed recaptions for training. A model trained with the recaption strategy produced images with noticeably finer details (e.g., distinct abalone contours, realistic sauce coatings on pork) compared to a model trained only on dish names, confirming that the strategy helps the model learn intricate visual features.
-   **Effect of Concept-Enhanced P2P:** The authors compared their proposed Concept-Enhanced P2P against vanilla P2P for creating editing data. For the task "add steam," vanilla P2P either failed to generate steam or produced inconsistent images. In contrast, Concept-Enhanced P2P successfully generated visible steam while preserving the structural consistency of the original image, proving its effectiveness in creating high-quality training data for complex edits.

## 6. Paper Figures
![Figure 10: Effect of our recaption strategy. The recaption help the model learn more details, such as the abalone in Fo Tiao Qiang and the sweet and sour sauce in Pot-fried pork.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_10.jpg' | relative_url }})
![Figure 2: Existing methods face challenges in generating photorealistic and faithful images of arbitrary Chinese dishes. Row 1 shows reference images that are real photographs.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_2.jpg' | relative_url }})
![Figure 3: Nuanced descriptions not only help Omni-Dish generate faithful dish images, but also endowing it with fine-grained instruction-following capabilities.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_3.jpg' | relative_url }})
![Figure 4: Overview of our method. In the yellow block, (a) with the dish curation and recaption, the coarse-to-fine strategy is applied to train Omni-Dish; (b) high-quality captions are obtained from a pre-constructed library and rewritten by large language models for inference. In the green block, (c) the Concept-Enhanced P2P approach is introduced to build the dish editing dataset; (d) a dish editing model is trained through a multi-task data mixture.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_4.jpg' | relative_url }})
![Figure 5: Dish name correction by two steps. For details, refer to Data Correction in Sec. 3.1.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_5.jpg' | relative_url }})
![Figure 6: Concept-Enhanced P2P can enhance editing effects while maintaining consistency.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_6.jpg' | relative_url }})
![Figure 7: Visual comparison of different models in dish generation. Row 1 displays authentic photos for readers unfamiliar with the dish, with detailed Chinese dish descriptions available in the appendix. Images in the left three columns have a resolution of 1024×1024 pixels, whereas images in the right two columns are 1024×768 pixels.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_7.jpg' | relative_url }})
![Figure 8: With the “low-refinement” tag, Omni-Dish generates less polished but more realistic and authentic images.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_8.jpg' | relative_url }})
![Figure 9: Visual comparison of different models in dish editing.]({{ '/images/04-2025/Omni-Dish:_Photorealistic_and_Faithful_Image_Generation_and_Editing_for_Arbitrary_Chinese_Dishes/figure_9.jpg' | relative_url }})
