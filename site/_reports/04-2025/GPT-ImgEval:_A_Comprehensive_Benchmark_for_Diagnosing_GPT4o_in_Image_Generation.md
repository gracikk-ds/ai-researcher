---
title: GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation
layout: default
date: 2024-04-05
---
![Figure 1: Commonly used pipelines for unified image generation and understanding, and potential decoder architectures of GPT4o’s image generation choice. The complete speculation of architectures can be seen in Figure 7 .]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_1.png' | relative_url }})

*Figure 1: Commonly used pipelines for unified image generation and understanding, and potential decoder architectures of GPT4o’s image generation choice. The complete speculation of architectures can be seen in Figure 7 .*


## 1. Motivation of the Paper
The authors address the need for a systematic and comprehensive evaluation of OpenAI's newly released GPT-4o model, whose impressive image generation and editing capabilities have generated significant excitement but lack a formal, public benchmark. The paper aims to fill this gap by introducing **GPT-ImgEval**, the first benchmark designed to quantitatively and qualitatively diagnose GPT-4o's performance, investigate its underlying architecture, identify its weaknesses, and assess its safety implications.

## 2. Key Ideas and Methodology
The core idea is to evaluate GPT-4o across three critical dimensions of image generation: general quality, instruction-based editing, and world-knowledge-informed synthesis.

The paper's key methodological contributions are:
*   **A Comprehensive Benchmark Suite:** The authors consolidate three existing, challenging datasets (GenEval, Reason-Edit, WISE) into a unified evaluation framework. Since no official API exists, they developed custom automation scripts to interact with the GPT-4o web interface for large-scale testing.
*   **Architecture Investigation:** The authors hypothesize that GPT-4o uses a hybrid architecture combining an autoregressive (AR) backbone with a diffusion-based decoder head. To test this, they propose a novel **classifier-based discrimination method**: they train a binary classifier to distinguish between images generated by known diffusion and autoregressive (VAR) models and then use it to classify GPT-4o's outputs.
*   **Systematic Weakness and Safety Analysis:** The work includes a detailed analysis of common failure modes and artifacts in GPT-4o's outputs, a comparative study against Google's Gemini 2.0 Flash, and an assessment of the detectability of its generated images by forensic models.

## 3. Datasets Used / Presented
The evaluation is performed on three existing datasets:
*   **GenEval:** Used to assess compositional text-to-image generation capabilities, focusing on object counting, color consistency, and spatial relationships.
*   **Reason-Edit:** A benchmark for instruction-guided image editing, testing the model's ability to follow complex commands involving spatial reasoning, object manipulation, and color changes.
*   **WISE (World knowledge-Informed Semantic Evaluation):** Used to evaluate the model's capacity to generate images grounded in real-world knowledge, such as cultural landmarks, scientific concepts, and historical context.

## 4. Main Results
*   **State-of-the-Art Performance:** GPT-4o significantly outperforms all prior models across all three benchmarks. It achieved an overall score of **0.84 on GenEval**, a remarkable score of **0.929 on Reason-Edit** (a +0.357 improvement over the previous best model), and a **WiScore of 0.80 on WISE**, demonstrating superior capabilities in compositional reasoning, instruction following, and knowledge integration.
*   **Architectural Insight:** The classifier-based analysis provides strong empirical evidence that GPT-4o employs a **diffusion-based head** for image decoding.
*   **Identified Weaknesses:** The model exhibits limitations, including a bias towards over-refinement and high-resolution outputs, inconsistencies in preserving image content when no edits are requested, a warm color bias, and difficulties generating coherent multi-person scenes or non-English text.
*   **High Detectability:** GPT-4o generated images are easily detected by existing forensic models (over 95% accuracy), likely due to artifacts from an internal super-resolution process.

## 5. Ablation Studies
While not a traditional ablation study, the paper performs a crucial analytical experiment to validate its hypothesis about GPT-4o's architecture.

*   **Experiment:** A binary classifier (fine-tuned CLIP-ViT) was trained to distinguish between images generated by a known diffusion-based model (Flux-1) and a known autoregressive model (VAR-Infinity).
*   **Result:** When this classifier was applied to images generated by GPT-4o, it consistently classified them as **diffusion-based**. This result provides strong evidence supporting the hypothesis that GPT-4o uses a diffusion head for image generation, rather than a purely autoregressive approach like VAR.

## 6. Paper Figures
![Figure 10: Failure Cases and Limitations of GPT-4o. We identify several scenarios in which GPT-4o may fail, along with common artifacts present in its generated images.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_10.png' | relative_url }})

*Figure 10: Failure Cases and Limitations of GPT-4o. We identify several scenarios in which GPT-4o may fail, along with common artifacts present in its generated images.*


![Figure 2: The overall workflow of our GPT-ImgEval , consisting the GPT-4o Image generation, Evaluation, and Analysis.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_2.png' | relative_url }})

*Figure 2: The overall workflow of our GPT-ImgEval , consisting the GPT-4o Image generation, Evaluation, and Analysis.*


![Figure 3: Examples of generation results of GPT4o using GenEval [ 18 ], covering single object, two objects, counting, colors, position, and attribute binding.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_3.png' | relative_url }})

*Figure 3: Examples of generation results of GPT4o using GenEval [ 18 ], covering single object, two objects, counting, colors, position, and attribute binding.*


![Figure 4: Quantitative results of model editing under the Reason-Edit benchmark [ 22 ]. We compare the performance of GPT4o with seven other SOTA image editing models. We see that GPT4o significantly outperforms other models.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_4.png' | relative_url }})

*Figure 4: Quantitative results of model editing under the Reason-Edit benchmark [ 22 ]. We compare the performance of GPT4o with seven other SOTA image editing models. We see that GPT4o significantly outperforms other models.*


![Figure 5: Examples of model editing results. We visualize the qualitative results of GPT4o with the other four SOTA editing generation methods. We use the Reason-Edit [ 22 ] benchmark for evaluation.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_5.png' | relative_url }})

*Figure 5: Examples of model editing results. We visualize the qualitative results of GPT4o with the other four SOTA editing generation methods. We use the Reason-Edit [ 22 ] benchmark for evaluation.*


![Figure 6: Visual examples of generation results on the WISE benchmark [ 32 ]. We visualize the qualitative results of GPT4o under different evaluation scenarios, following the WISE benchmark.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_6.png' | relative_url }})

*Figure 6: Visual examples of generation results on the WISE benchmark [ 32 ]. We visualize the qualitative results of GPT4o under different evaluation scenarios, following the WISE benchmark.*


![Figure 7: We present a complete architectural speculation, proposing four possible candidates that differ in their choice of visual encoder while all share a diffusion-based head for image decoding.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_7.png' | relative_url }})

*Figure 7: We present a complete architectural speculation, proposing four possible candidates that differ in their choice of visual encoder while all share a diffusion-based head for image decoding.*


![Figure 8: An "easter-egg" example officially provided by OpenAI, which aligns the potential architecture-(a) in Figure 1 .]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_8.png' | relative_url }})

*Figure 8: An "easter-egg" example officially provided by OpenAI, which aligns the potential architecture-(a) in Figure 1 .*


![Figure 9: The overall workflow of the proposed model-based discrimination method.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_9.png' | relative_url }})

*Figure 9: The overall workflow of the proposed model-based discrimination method.*
