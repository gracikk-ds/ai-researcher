---
title: GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation
layout: default
date: 2025-04-03
---
## GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation
**Authors:**
- Zhiyuan Yan
- Li Yuan

**ArXiv URL:** http://arxiv.org/abs/2504.02782v3

**Citation Count:** 24

**Published Date:** 2025-04-03

![Figure 1: Commonly used pipelines for unified image generation and understanding, and potential decoder architectures of GPT4oâ€™s image generation choice. The complete speculation of architectures can be seen in Figure 7 .]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
The recent release of OpenAI's GPT-4o demonstrated surprisingly powerful capabilities in image generation and editing, creating significant excitement. However, there was no systematic benchmark to quantitatively and qualitatively assess its performance. The authors address this gap by introducing **GPT-ImgEval**, the first comprehensive benchmark designed to diagnose GPT-4o's image generation abilities, uncover its underlying architecture, identify its weaknesses, and evaluate its safety implications.

## 2. Key Ideas and Methodology
The paper's core contribution is a multi-faceted evaluation framework for GPT-4o. The methodology is centered on three key activities:

*   **Comprehensive Benchmarking:** The authors evaluate GPT-4o's performance across three critical dimensions:
    1.  **Generation Quality:** Assessed on compositional attributes like object counting, color, and spatial relations.
    2.  **Editing Proficiency:** Measured on its ability to follow complex editing instructions while preserving non-edited regions.
    3.  **World Knowledge:** Tested on its capacity to generate images that require understanding of cultural, scientific, and commonsense concepts.
*   **Architecture Investigation:** To infer the internal architecture of the black-box GPT-4o model, the authors propose a novel classifier-based discrimination method. They trained a binary classifier to distinguish between images generated by autoregressive (VAR-based) models and diffusion-based models. This trained classifier was then used to predict the origin of images generated by GPT-4o.
*   **Automation for Evaluation:** Since GPT-4o lacked an official API for image generation at the time of writing, the authors developed custom automation scripts to interact with the web interface, enabling large-scale, repeatable experiments.

## 3. Datasets Used / Presented
The evaluation relies on three existing, well-established datasets, each targeting a different capability:

*   **GenEval:** Used for text-to-image generation evaluation. It provides an object-centric framework to assess compositional abilities, including object counting, spatial arrangement, and color consistency.
*   **Reason-Edit:** A benchmark specifically designed for instruction-based image editing. It tests the model on complex challenges like spatial reasoning, object replacement, and attribute manipulation.
*   **WISE (World knowledge-Informed Semantic Evaluation):** Used to evaluate the model's ability to generate images grounded in real-world knowledge, such as cultural landmarks, historical context, and scientific concepts, going beyond simple text-image alignment.

## 4. Main Results
The paper reports that GPT-4o demonstrates state-of-the-art performance across all evaluated tasks, significantly surpassing previous models.

*   **Quantitative Performance:**
    *   On **GenEval** (generation), GPT-4o achieved an overall score of **0.84**, outperforming all prior models, including specialized text-to-image systems.
    *   On **Reason-Edit** (editing), it scored a remarkable **0.929**, representing a massive improvement over the previous best model's score of 0.572.
    *   On **WISE** (knowledge), it achieved a score of **0.80**, drastically outperforming other models which scored below 0.50.
*   **Architectural Insight:** The classifier-based analysis strongly suggests that GPT-4o employs a hybrid architecture consisting of an **autoregressive (AR) model combined with a diffusion-based head** for image decoding, rather than a purely autoregressive (VAR-like) architecture.
*   **Key Limitations:** The analysis also identified several weaknesses, including: inconsistencies in image reproduction, a bias towards over-refining and sharpening images, non-localized edits when using the brush tool, failures in generating coherent multi-person scenes, and poor performance on non-English text.
*   **Detectability:** Images generated by GPT-4o are highly detectable by existing forensic models (over 95% accuracy), likely due to artifacts introduced by an internal super-resolution process.

## 5. Ablation Studies
Not performed. The paper analyzes a pre-existing, black-box model (GPT-4o) and does not propose a new architecture of its own. Therefore, traditional ablation studies (i.e., removing components of their own model to measure impact) are not applicable. However, the **classifier-based analysis of GPT-4o's architecture** serves a similar purpose by systematically investigating and providing evidence for a specific architectural hypothesis over another.

## 6. Paper Figures
![Figure 10: Failure Cases and Limitations of GPT-4o. We identify several scenarios in which GPT-4o may fail, along with common artifacts present in its generated images.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_10.jpg' | relative_url }})
![Figure 2: The overall workflow of our GPT-ImgEval , consisting the GPT-4o Image generation, Evaluation, and Analysis.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_2.jpg' | relative_url }})
![Figure 3: Examples of generation results of GPT4o using GenEval [ 18 ], covering single object, two objects, counting, colors, position, and attribute binding.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_3.jpg' | relative_url }})
![Figure 4: Quantitative results of model editing under the Reason-Edit benchmark [ 22 ]. We compare the performance of GPT4o with seven other SOTA image editing models. We see that GPT4o significantly outperforms other models.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_4.jpg' | relative_url }})
![Figure 5: Examples of model editing results. We visualize the qualitative results of GPT4o with the other four SOTA editing generation methods. We use the Reason-Edit [ 22 ] benchmark for evaluation.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_5.jpg' | relative_url }})
![Figure 6: Visual examples of generation results on the WISE benchmark [ 32 ]. We visualize the qualitative results of GPT4o under different evaluation scenarios, following the WISE benchmark.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_6.jpg' | relative_url }})
![Figure 7: We present a complete architectural speculation, proposing four possible candidates that differ in their choice of visual encoder while all share a diffusion-based head for image decoding.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_7.jpg' | relative_url }})
![Figure 8: An "easter-egg" example officially provided by OpenAI, which aligns the potential architecture-(a) in Figure 1 .]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_8.jpg' | relative_url }})
![Figure 9: The overall workflow of the proposed model-based discrimination method.]({{ '/images/04-2025/GPT-ImgEval:_A_Comprehensive_Benchmark_for_Diagnosing_GPT4o_in_Image_Generation/figure_9.jpg' | relative_url }})
