---
title: CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models
layout: default
date: 2025-04-07
---
![Figure 1. We introduce CREA, an agentic framework that emulates the human creative process for creative image editing and generation. Our approach is driven by collaborative interactions between specialized agents, such as a Creative Director and an Art Critic , who communicate to refine and enhance creative output. Moreover, our approach can be extended to video domain for creative video generation. Our framework can also be integrated with personalization techniques to further enrich and expand creative workflows.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
Existing generative AI models, while capable of producing high-quality images, often lack true originality and artistic depth. They typically rely on extensive user effort through tedious prompt engineering and manual refinement to achieve creative results. The authors address this gap by introducing the task of "creative image editing," which aims to autonomously transform images in novel, expressive, and aesthetically rich ways with minimal user intervention. The core problem is to shift the creative burden from the user to the AI system itself, enabling more autonomous artistic exploration.

## 2. Key Ideas and Methodology
The paper introduces **CREA (Creative Collaborative Agentic Framework)**, a novel multi-agent system designed to mimic the collaborative human creative process. The core idea is to structure creativity as a dynamic, iterative dialogue between specialized AI agents.

The methodology involves a team of five agents built on the AutoGen framework:
*   **Creative Director:** Orchestrates the process and defines the creative vision.
*   **Prompt Architect:** Translates the vision into detailed, contrastive prompts.
*   **Generative Executor:** Uses diffusion models (e.g., FLUX, ControlNet) to generate or edit images.
*   **Art Critic:** Evaluates the output using a multimodal LLM against six established creativity principles (Originality, Expressiveness, Aesthetic Appeal, Technical Execution, Unexpected Associations, Interpretability & Depth).
*   **Refinement Strategist:** Proposes improvements based on the critic's feedback.

The workflow proceeds in four stages: Pre-Generation Planning, Image Generation/Editing, Post-Generation Evaluation, and an iterative Self-Enhancement loop. This process optimizes a "Creativity Index" (CI) to ensure the final output is both coherent and highly creative.

## 3. Datasets Used / Presented
The authors did not use a standard training dataset but created a custom evaluation set to test their framework.
*   **Evaluation Set:** For quantitative analysis, they used 24 different object concepts. For each concept, 25 prompts were used for both editing and generation tasks, resulting in a total of 600 images evaluated per task.
*   **User Study:** A user study was conducted on the Prolific platform with 50 participants. They were asked to rate a diverse set of images generated by CREA and baseline methods on criteria such as accuracy, novelty, and editing consistency.

## 4. Main Results
CREA demonstrated superior performance over state-of-the-art methods in both quantitative metrics and human evaluations.
*   **Creative Editing:** CREA significantly outperformed baselines like LEDITS++, InstructPix2Pix, and SDEdit across all metrics, showing higher diversity (LPIPS, VENDI), better prompt alignment (CLIP), and superior structural preservation (DINO).
*   **Creative Generation:** Compared to models like SDXL, Flux, and ConceptLab, CREA produced significantly more diverse and varied results (higher LPIPS and VENDI scores).
*   **User and LLM Evaluation:** Both human participants and an LLM-as-a-judge consistently rated CREA's outputs as more creative, original, and aesthetically appealing than those from all competing methods. The authors conclude that their agentic framework successfully fosters creativity and reduces the need for direct user guidance.

## 5. Ablation Studies
The authors performed several ablation studies to validate their design choices.
*   **Model Components:** An ablation on the framework's components showed that the full system, including creativity principles, contrastive prompting, and self-enhancement, achieved the highest performance. Removing these components led to a progressive drop in diversity and creativity scores.
*   **Iterative Refinement:** The benefit of the multi-iteration self-enhancement process was demonstrated, showing that creative quality improves with each refinement loop.
*   **Model Generalization:** The framework's effectiveness was confirmed with different backbone T2I models, including SDXL and DALL-E, highlighting its versatility.
*   **Prompt Variations:** Experiments with alternative prompting strategies, such as using negative prompts (e.g., "a normal object"), showed that the framework can be effectively steered to avoid conventional outputs.

## 6. Paper Figures
![Figure 2. CREA Framework . We introduce a collaborative multi-agent framework for creative image editing and generation. Our framework consists of four stages, 1.a Pre-Generation Planning, 1.b Creative Image Generation/Editing, 2. Post-Generation Evaluation and 3. Self-Enhancement. Here, K is the number of maximum iterations.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_2.jpg' | relative_url }})
![Figure 3. Qualitative Results for Creative Image Editing and Generation Tasks. (a) Qualitative results illustrating CREA’s disentangled creative edits. (b) Generation results across diverse objects and domains, demonstrating CREA’s ability to produce a wide range of creative variations. For more results, please visit Supplementary Material.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_3.jpg' | relative_url }})
![Figure 4. Qualitative Comparison of Creative Image Editing Task. We compare CREA with state-of-the-art editing methods. As shown, CREA successfully reimagines objects into creative variants in a disentangled manner, whereas other approaches either fail to produce distinctly creative edits or introduce unintended alterations.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_4.jpg' | relative_url }})
![Figure 5. Qualitative Comparison of Creative Image Generation Task. We compare CREA with ConceptLab, SDXL and Flux. CREA consistently produces diverse and creative generations across multiple domains.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_5.jpg' | relative_url }})
![Figure 6. Creative applications of our method beyond image generation and editing. (a) Users can steer the creative process with additional conditions such as ‘Monster’. (b) CREA-generated images can be leveraged for personalization in creative domains.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_6.jpg' | relative_url }})
![Figure 7. Ablation Study. We perform comprehensive ablation studies to analyze the design choices of CREA: (a) Model Generalization: Our method extends effectively to different generative models, such as SDXL and DALL-E. (b) Parameter Sensitivity: We ablate CFG values for Flux and the conditioning scale for ControlNet to evaluate their impact. (c) Iterative Refinement: We demonstrate the benefits of our method’s refinement process over multiple iterations. (d) Prompt Variations: We explore alternative prompts beyond ‘a creative <obj> ’. For additional ablation results, please refer to Table 3 .]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_7.jpg' | relative_url }})
![Figure 8. Video Generation . Comparison between baseline generations from CogVideoX and outputs generated using our creative agentic pipeline. Our method enables the creation of visually diverse and creative video scenes.]({{ '/images/04-2025/CREA:_A_Collaborative_Multi-Agent_Framework_for_Creative_Content_Generation_with_Diffusion_Models/figure_8.jpg' | relative_url }})
