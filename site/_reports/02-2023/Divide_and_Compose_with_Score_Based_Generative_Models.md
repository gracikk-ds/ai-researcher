---
title: Divide_and_Compose_with_Score_Based_Generative_Models
layout: default
date: 2023-02-05
---
## Divide and Compose with Score Based Generative Models
**Authors:**
- Sandesh Ghimire
- Jennifer Dy

**ArXiv URL:** http://arxiv.org/abs/2302.02272v1

**Citation Count:** 0

**Published Date:** 2023-02-05

![Figure 1. Using all score components results in faithful reconstruction, but with interesting variations]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_1.jpg' | relative_url }})
## 1. Motivation of the Paper
The authors address the limited control and interpretability of existing score-based (diffusion) generative models. While text-to-image models can generate diverse images, users lack fine-grained control to edit specific attributes of the output beyond changing the entire text prompt. The relationship between the conditioning (e.g., text embedding) and the final image is opaque. This paper aims to bridge this gap by proposing a method to learn distinct, interpretable image components in an unsupervised manner, which can then be individually manipulated and composed to edit images in a more controlled and informed way.

## 2. Key Ideas and Methodology
The core idea is to decompose the score function of a generative model into a sum of multiple, distinct score components. This is inspired by Energy-Based Models (EBMs), where the total energy of a system is a sum of individual energy functions, making the log-probability (and its gradient, the score) additive.

The methodology is an autoencoder-like framework:
-   An **encoder** network takes a single image and maps it to `K` separate latent vectors.
-   A shared **score network** (a U-Net with Adaptive Group Normalization, AdaGN) is conditioned on each of the `K` latent vectors to produce `K` corresponding score components.
-   The final score function for reconstructing the image is the average of these `K` components.
-   The model is trained by optimizing a single-image log-likelihood objective, which is practically implemented as a denoising score-matching loss, to ensure the combined score function can reverse the diffusion process back to the original image.

This approach forces the model to learn a disentangled representation where each score component captures a different, meaningful aspect of the image.

## 3. Datasets Used / Presented
The authors evaluate their method on four standard computer vision datasets to demonstrate its versatility:
-   **Celeb-A:** A dataset of celebrity faces, used to show decomposition of facial features like smile and hair.
-   **LSUN-Church:** A dataset of outdoor church images, used to disentangle background, color, and architectural elements.
-   **Cifar-10:** A dataset of small, low-resolution object images.
-   **SVHN:** A dataset of house numbers, used to separate digit shapes from texture and lighting.

All images were resized to 32x32 or 48x48 for the experiments.

## 4. Main Results
The paper successfully demonstrates that the proposed decomposition yields interpretable and controllable components.
-   **Visualization:** By generating images using only a single score component, the authors show that the components learn semantically meaningful attributes. For example, on Celeb-A, one component captures the "smile," while others capture hair or face shape.
-   **Manipulation:** The primary result is the ability to perform controlled image editing. By linearly interpolating a specific component with an unconditional score (or re-weighting components), the authors can modify one aspect of an image while preserving others. For instance, they can alter the background of a church while keeping the building's architecture intact, or change a person's smile without affecting their identity.

The authors claim their novel decomposition provides a new way to achieve interpretability and control in score-based models, akin to "dreaming" by composing learned concepts.

## 5. Ablation Studies
The paper includes an ablation study on the number of components, `K`.
-   **Experiment:** They trained models on Cifar-10 with `K=3` and `K=5` components and compared the generated components.
-   **Impact:** The model with five components learned some factors similar to the three-component model but also captured new, more specific concepts. For example, a new component emerged that seemed to capture a specific colored pattern and shape. This suggests that increasing `K` allows the model to learn a more fine-grained decomposition of the data.

## 6. Paper Figures
![Figure 2. Visualizing different score components through generation as a way to interpret components. Images are generated by solving reverse SDE using single score component. Each row is a component and each column is different dataset.]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_2.jpg' | relative_url }})
![Figure 3. First row shows different components. Second row shows the effect of slowly diluting ﬁrst component with unconditional score function. Decreasing α means weight of ﬁrst component decreases and that of unconditional score function increases.]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_3.jpg' | relative_url }})
![Figure 4. First component is diluted with unconditional score function]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_4.jpg' | relative_url }})
![Figure 5. Second and third components are diluted with unconditional score function in second row.]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_5.jpg' | relative_url }})
![Figure 6. Second row: Changing the relative weight of ﬁrst and second components while keeping the third component constant.]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_6.jpg' | relative_url }})
![Figure 7. Visualizing three and ﬁve components in Cifar10 datase through image generation from components.]({{ '/images/02-2023/Divide_and_Compose_with_Score_Based_Generative_Models/figure_7.jpg' | relative_url }})
