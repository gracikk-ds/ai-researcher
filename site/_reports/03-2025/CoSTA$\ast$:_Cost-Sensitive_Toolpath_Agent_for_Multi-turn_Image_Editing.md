---
title: CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing
layout: default
date: 2025-03-13
---
## CoSTA$\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing
**Authors:**
- Advait Gupta
- Tianyi Zhou

**ArXiv URL:** http://arxiv.org/abs/2503.10613v1

**Citation Count:** 0

**Published Date:** 2025-03-13

![Figure 2. Comparison of CoSTA ∗ with State-of-the-Art image editing models/agents, which include GenArtist ( Wang et al. , 2024b ), MagicBrush ( Zhang et al. , 2024a ), InstructPix2Pix ( Brooks et al. , 2023 ), and CLOVA ( Gao et al. , 2024 ). The input images and prompts are shown on the left of the figure. The outputs generated by each method illustrate differences in accuracy, visual coherence, and the ability to multimodal tasks. Figure 9 shows examples of step-by-step editing using CoSTA ∗ with intermediate subtask outputs presented.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_2.jpg' | relative_url }})
## 1. Motivation of the Paper
The authors address the challenge that modern text-to-image models, such as Stable Diffusion and DALL-E, struggle with complex, multi-turn image editing tasks that require a sequence of precise modifications. Existing agentic approaches to solve this by chaining AI tools are either computationally expensive (e.g., conventional search algorithms) or prone to failure due to inaccurate planning (e.g., LLM-only agents). Furthermore, these systems lack a mechanism for users to control the trade-off between the final image quality and the computational cost (e.g., execution time) required to produce it.

## 2. Key Ideas and Methodology
The paper introduces **CoSTA*** (Cost-Sensitive Toolpath Agent), a hierarchical agent that combines a Large Language Model (LLM) for high-level planning with an A* search algorithm for cost-sensitive tool selection. The core methodology involves three stages:
1.  **Task Decomposition**: An LLM first decomposes a complex user instruction into a structured "subtask tree," defining a high-level plan with potential parallel paths.
2.  **Tool Subgraph Construction**: This subtask tree is used to prune a large, pre-defined **Tool Dependency Graph (TDG)**, creating a much smaller, task-relevant subgraph of available AI tools. The TDG is automatically built from a **Model Description Table (MDT)** that specifies each tool's capabilities, inputs, and outputs.
3.  **Cost-Sensitive A* Search**: The A* algorithm searches this small subgraph to find the optimal sequence of tools (toolpath). The search is guided by a heuristic function that combines pre-computed benchmark data on tool cost and quality. A user-controlled parameter, `α`, allows for explicit trade-offs between cost and quality. During execution, a Vision-Language Model (VLM) validates the output of each step; failures trigger a real-time update of the tool's cost, enabling the agent to recover and explore alternative paths.

## 3. Datasets Used / Presented
The authors introduce a new benchmark dataset specifically for multi-turn image editing.
*   **Name**: Not explicitly named, but referred to as their "proposed benchmark".
*   **Size and Domain**: It consists of 121 manually curated image-task pairs. The tasks are complex, involving 1 to 8 subtasks per prompt. The dataset is diverse, containing 81 image-only editing tasks and 40 multimodal tasks that require both image and text manipulation (e.g., editing text within an image).
*   **Usage**: The dataset was used to evaluate CoSTA* against state-of-the-art baselines and for the ablation studies. A subset of its images (137 instances across 121 images) was also used to benchmark individual tools to populate the heuristic table for the A* search.

## 4. Main Results
CoSTA* significantly outperforms existing agentic and image-editing models in both accuracy and cost-efficiency.
*   On the new benchmark, CoSTA* achieves an overall human-evaluated accuracy of **94%**, while the next-best baseline, GenArtist, scores **73%**. The performance gap is especially pronounced on complex tasks with more than 5 subtasks and on multimodal tasks requiring text manipulation.
*   The authors demonstrate that CoSTA* achieves Pareto optimality. By adjusting the trade-off parameter `α`, it can generate various outputs that dominate all baselines on a cost-vs-quality plot, offering better quality for a similar cost or lower cost for similar quality.

## 5. Ablation Studies
Two key ablation studies were performed to validate CoSTA*'s design components:

1.  **Impact of Real-time Feedback**: The study compared the full CoSTA* model (using both pre-computed heuristics `h(x)` and real-time cost updates `g(x)`) against a version using only the static heuristics `h(x)`. On a set of 35 high-risk tasks, integrating real-time feedback **improved accuracy from 79.8% to 92.3%**, demonstrating that dynamically penalizing failed tools and re-planning is crucial for robust performance.
2.  **Impact of Multimodality Support**: This study tested CoSTA*'s performance on 30 text-in-image editing tasks against tools designed primarily for image editing (e.g., DALL-E, Stable Diffusion). CoSTA*, with its specialized toolset for text, achieved **93% accuracy**, whereas the image-only tools struggled and only reached **48% accuracy**. This highlights the necessity of a diverse, multimodal toolset for handling complex, real-world editing requests.

## 6. Paper Figures
![Figure 3. Comparison of CoSTA ∗ with other planning agents. LLM-only planning is efficient but prone to failure and heuristics. Search algorithms like A ∗ guarantee optimal paths but are computationally expensive. CoSTA ∗ balances cost and quality by first pruning the subtask tree using an LLM, which reduces the graph of tools we conduct fine-grained A ∗ search on.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_3.jpg' | relative_url }})
![Figure 5. Three stages in CoSTA ∗ : (1) an LLM generates a subtask tree based on the input and task dependencies; (2) the subtask tree spans a tool subgraph that maintains tool dependencies; and (3) A ∗ search finds the best toolpath balancing efficiency and quality.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_5.jpg' | relative_url }})
![Figure 6. Distribution of image-only (left) and text+image tasks (middle) in our proposed benchmark, and quality comparison of different methods on the benchmark (right). CoSTA ∗ excels in complex multimodal tasks and outperforms all the baselines.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_6.jpg' | relative_url }})
![Figure 7. Comparison of a task with h ( x ) and h ( x ) + g ( x ) , showing how real-time feedback improves path selection and execution.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_7.jpg' | relative_url }})
![Figure 8. Qualitative comparison of image editing tools vs. CoSTA ∗ for text-based tasks, highlighting the advantages of our multimodal support in preserving visual and textual fidelity.]({{ '/images/03-2025/CoSTA$\ast$:_Cost-Sensitive_Toolpath_Agent_for_Multi-turn_Image_Editing/figure_8.jpg' | relative_url }})
