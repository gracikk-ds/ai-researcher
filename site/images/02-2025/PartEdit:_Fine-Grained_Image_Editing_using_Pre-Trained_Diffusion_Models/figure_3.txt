Fig. 3. An overview of our proposed approach for fine-grained part editing. For an object part ğ‘ , we collect a dataset of images I ğ‘ and their corresponding part annotation masks Y ğ‘ . To optimize a textual token to localize this part, we initialize a random textual embedding Ë† ğ¸ that initially generates random cross-attention maps. During optimization, we invert images in I ğ‘ and optimize the part token so that the cross-attention maps at different layers and timesteps match the part masks in Y ğ‘ . After optimizing the token, it can be used during inference to produce a localization mask at each denoising step. These localization masks are used to perform feature bending between the source and the edit image trajectories. Note that we visualize three instances of SDXL [ Podell et al. 2024 ] for illustration, but in practice, this is done with the same model in a batch of three.