Fig. 4. Inverse diffusion with classifier-guided resampling: To adapt an input image ğ¼ , it is first encoded into a latent vector ğ‘§ 0 = ğ¸ ( ğ¼ ) and then inverted to its corresponding noise vector ğ‘§ ğ‘‡ = ğ·ğ·ğ¼ğ‘€ inv ( ğ‘§ 0 ,ğ‘¡, C , ğ›½ ) , while generating unconditional text embeddings for each timestep {âˆ… ğ‘¡ } ğ‘‡ ğ‘¡ = 1 = ğ‘ğ‘‡ğ‘‚ ([ ğ‘§ ğ‘‡ , . . . ,ğ‘§ 0 ] , C) . At each step of the denoising process, Ë† ğ‘§ ğ‘¡ is updated by blending the predicted unconditional and conditional noise ğœ– ğœƒ , further refined by a score âˆ‡ ğ‘§ ğ‘¡ that quantifies alignment with the emotional reference . With the resulting noise vector Ëœ ğœ– ğœƒ , Ë† ğ‘§ ğ‘¡ âˆ’ 1 can be obtained. The final latent vector Ë† ğ‘§ 0 is decoded into the image Ë† ğ¼ = ğ· ( Ë† ğ‘§ 0 ) , which closely resembles ğ¼ while modulating the emotional response.