Fig. 4. Inverse diffusion with classifier-guided resampling: To adapt an input image 𝐼 , it is first encoded into a latent vector 𝑧 0 = 𝐸 ( 𝐼 ) and then inverted to its corresponding noise vector 𝑧 𝑇 = 𝐷𝐷𝐼𝑀 inv ( 𝑧 0 ,𝑡, C , 𝛽 ) , while generating unconditional text embeddings for each timestep {∅ 𝑡 } 𝑇 𝑡 = 1 = 𝑁𝑇𝑂 ([ 𝑧 𝑇 , . . . ,𝑧 0 ] , C) . At each step of the denoising process, ˆ 𝑧 𝑡 is updated by blending the predicted unconditional and conditional noise 𝜖 𝜃 , further refined by a score ∇ 𝑧 𝑡 that quantifies alignment with the emotional reference . With the resulting noise vector ˜ 𝜖 𝜃 , ˆ 𝑧 𝑡 − 1 can be obtained. The final latent vector ˆ 𝑧 0 is decoded into the image ˆ 𝐼 = 𝐷 ( ˆ 𝑧 0 ) , which closely resembles 𝐼 while modulating the emotional response.