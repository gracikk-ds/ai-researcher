Figure 2. Overview of EditAR, which can take various types of image conditions to perform image editing or translation. An image I c is mapped through a VQ-Encoder E I to obtain corresponding token indices. Corresponding text instructions are mapped to latent embeddings c T via a text encoder E T . Both image token indices and text embeddings are input to the autoregressive transformer F to predict the target token indices s . To enhance the text-to-image alignment, a distillation loss is introduced during training to minimize the differences between the latent features of the autoregressive model, F and that of a feature encoder E distill . The output sequence s is lastly decoded into a realistic image via a VQ-Decoder D I during inference.