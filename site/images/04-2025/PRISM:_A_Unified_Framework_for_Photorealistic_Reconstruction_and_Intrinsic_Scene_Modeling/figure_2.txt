Fig. 2. Pipeline of our PRISM model. RGB image and its corresponding X intrinsic channels are encoded into latent space via a fixed VAE Encoder. A Diffusion Transformer is applied on the tokens of the latent of all channels simultaneously and conditioned by the text embedding from an input text prompt. Denoised tokens are passing through a fixed decoder for RGB+X generation. During training, intrinsic channels are randomly ablated which makes PRISM a unified framework for text-to-image generation, intrinsic decomposition, and conditional image generation with any subset of intrinsic images.