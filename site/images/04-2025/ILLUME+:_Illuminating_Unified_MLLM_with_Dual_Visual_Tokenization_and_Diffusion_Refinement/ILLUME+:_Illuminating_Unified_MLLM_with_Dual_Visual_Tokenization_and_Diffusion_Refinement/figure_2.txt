Figure 2: Characteristics comparison among existing unified models. Existing methods explore distinct paradigms to balance visual understanding, generation, and editing capabilities. Early approaches using VQGAN discretization struggle in understanding and context-aware generation tasks due to limited semantic alignment. Later frameworks incorporate semantic encoders, achieving better alignment but compromising texture preservation essential for fine-grained editing. ILLUME+ deep-integrates image understanding, generation, and editing into a single, unified architecture, enabling more intelligent and flexible interactions and task execution.