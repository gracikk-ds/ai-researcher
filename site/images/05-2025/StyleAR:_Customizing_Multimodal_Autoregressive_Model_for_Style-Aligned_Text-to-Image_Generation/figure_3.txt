Figure 3: The framework of our StyleAR. During training, we utilize a frozen CLIP [ 24 ] image encoder along with a trainable perceiver [ 13 ; 1 ] resampler module to efficiently extracted features. Subsequently, style tokens are combined with the injected Gaussian noise and concatenated with multimodal tokens by replacing the placeholder tokens. During inference, we incorporate SAM [ 15 ] to remove irrelevant semantic contents in the reference style image.