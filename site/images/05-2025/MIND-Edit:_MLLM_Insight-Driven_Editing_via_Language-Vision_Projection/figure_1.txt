Figure 1: Overview of the proposed MIND-Edit framework. MIND-Edit takes text instructions, original images, and optional editing masks as inputs. It integrates an instruction optimization strategy and an MLLM insight-driven image editing strategy, jointly optimizing instructions and generating visual representations to guide the diffusion model in creating semantically accurate edited images.