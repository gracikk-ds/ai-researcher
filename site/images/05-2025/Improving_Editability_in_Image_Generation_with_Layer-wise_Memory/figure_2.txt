Figure 2. Overview. (a) The left denotes an illustration of how Multi Query Disentanglement is performed in the cross-attention layer. (b) The upper right figure shows Background Consistency Guidance with recalled latents, conducting latent blending with the saved latents. (c) The right below shows the layer-wise memory, saving the previous editing stepsâ€™ latents, masks, and prompt embeddings.