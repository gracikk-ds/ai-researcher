Figure 2. Overview of our method. (a) Prompt Augmentation: In order to augment the prompts to facilitate localised image editing we start by refining textual descriptions for source images using the BLIP captioning model [ 22 ], resulting in cleaner captions suitable for further processing. Subsequently, we augment this input prompt by generating a range of target prompts using masked language modeling and exploiting word relations. (b) Soft Contrastive Loss (Soft-CL): The augmented prompts are instrumental in computing an attention mask based on the differences between the generated images. This attention mask is used to bring the inverse masked areas of the generated images closer while pushing away masked areas considering their similarity to the prompts.