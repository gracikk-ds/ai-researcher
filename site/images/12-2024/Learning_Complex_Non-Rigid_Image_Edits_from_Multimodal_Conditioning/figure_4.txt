Figure 4. System diagram illustrating the process of generating a desired edit using multiple inputs including noise target latent, binary mask, masked target latent, reference image, and change of scene prompt. The Affordance Diffusion Network on the right is the formulation proposed by [ 16 ], our improvements to controllability come from the framework described on the left. We study combinations of pose and weakly annotated text conditioning to learn more controllable and complex image edits that still preserve the identity of a person in a scene. No other work to our knowledge combines controllable non-rigid edits with identity preservation, and works in the wild.