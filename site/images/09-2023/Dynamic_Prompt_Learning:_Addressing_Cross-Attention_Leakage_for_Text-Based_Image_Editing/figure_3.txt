Figure 3: After DDIM inversion, we visualize the average of each component over T timestamps for the input image in Fig. 1 (with the prompt: "a cat and a dog"). From left to right, they are cross-attention (CA) for each noun word, then PCA&clustering of the self-attention (SA), query, key and value representations. Here, the maps are simply resized without any interpolation to demonstrate their original views.