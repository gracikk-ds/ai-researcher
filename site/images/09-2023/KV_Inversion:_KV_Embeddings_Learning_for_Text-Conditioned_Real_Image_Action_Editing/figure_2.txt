Fig. 2: Pipeline of the proposed KV Inversion, which can be divided into 3 stages, inversion stage, tuning stage and editing stage. Inversion stage is for getting supervision. Tunning stage is for learning KV embedding for content preserving and editing stage is using the learned content for consistency editing results. itself as well as the text embedding on 5 images of the editing object, so the GPU memory and time cost required is too high. ELITE [43] requires training on a large dataset, which is even more expensive on time and GPU. MasaCtrl does not require training and finetuning, but its reconstruction performance on real images is unsatisfactory, making it difficult to editing. In our method, we aim to solve the problem of action editing without using multiple images of the same object for finetuning (generally known as Tuning-free in this field), without training the diffusion model itself, and without training on a large dataset for a long time (generally known as Training-free in this field), and to propose a solution to the mentioned challenges in the above setting. The core problem is how to preserve the content of the original object when the action changes. Our KV Inversion is divided into 3 stages. The fundamental difference with the concurrnet works [6, 12, 27] is that KV Inversion directly learns Key and Value at the self-attention layer to preserve the content of the source image by these learnable parameters (KV embeddings), which we call upgrading the original self-attention to Content Preserving self-attention (CPattn). Then, in the editing stage, we use the edit text prompt to introduce the action information and the learned KV embeddings to preserve the texture and identity of the object. We further control the timesteps of upgrading the CP-attn and the segmentation mask obtained by Segment Anything (SAM) [18], thus achieving a faster and more controllable editing. Our main contributions are summarized as follows. 1) We propose a training-free text-conditoned image action editing method KV Inversion to solve the action editing problem. 2) We design an upgrade version of self-attention named content preserving self-attention, which can preserve the texture and identity of the original object and then be used to fill the editing image. 3) Comprehensive Experiments show that KV Inversion can achieve satisfactory performance in real image editing.