Fig. 2: The overall pipeline for the diverse semantic image editing. During training, we both encode the erased and original images. The original image is encoded because if a semantic or instance ID is completely erased, then its style is extracted from the original image for the training. The encoded styles, instance maps, and binary mask are fed into the style encoding module which is explained in more detail in Sec. 3.1 . The outputs of the style encoding are used in the normalization layers of the generator. The normalization layers additionally take semantic maps, edge maps, and binary masks as inputs. As for the generator, we use a multi-scale generator that refines the predictions at each stage as explained in more depth in Sec. 3.2 .