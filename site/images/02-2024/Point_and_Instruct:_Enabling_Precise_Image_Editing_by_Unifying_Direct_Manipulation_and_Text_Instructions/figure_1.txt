Figure 1: Point & Instruct empowers users to specify image editing instructions that combine the expressively of natural language and the spatial precision of direct manipulation. We show an example of our method, which allows a user to move a particular dog to a precise location and change its appearance. (Left) A user can select which object in particular they wish to manipulate with a bounding box, and specify a location to move the object to with a star. These geometric shapes can be referenced in a natural language instruction symbolically and combined with language only instructions that specify changes to the appearance of objects. (Right) For comparison we show how the popular text-based editing system InstructPix2Pix [ 3 ] fails at this task. Not only does this system require a much more verbose query to convey the same image edit, but it also fails to move objects and fails to localize changes to the correct objects.