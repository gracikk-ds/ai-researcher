Figure 2. Overview of DreamMix . During finetuning, we use the source data { x s , p s } along with regular data { x r , p r } constructed via an attribute decoupling mechanism (Sec. 3.3 ), to enable pretrained Text-to-Image (T2I) inpainting models to efficiently adapt to subject generation. At testing, we employ a disentangled inpainting framework (Sec. 3.2 ), which divides the denoising process into two stages: Local Content Generation (LCG) and Global Context Harmonization (GCH). Additionally, we propose a textual attribute substitution module (Sec. 3.4 ) to generate a decomposed text embedding to enhance the editability of our method during testing.