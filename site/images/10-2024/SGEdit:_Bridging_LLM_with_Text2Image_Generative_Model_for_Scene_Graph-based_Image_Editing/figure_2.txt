Fig. 2. Our pipeline consists of two main stages: scene parsing and image editing. In the scene parsing stage, the input image is processed by our LLM-driven scene parser, which creates a scene graph and annotations for nodes such as object masks and captions. The node annotations allow for the fine-tuning of the diffusion model, representing each object in the scene with an optimized token and a specific prompt. During the image editing stage, the LLM editing controller translates user manipulations on the scene graph into a sequence of operations with text prompts and directs the targeted edits to specific regions. These edits are implemented by applying attention modulation to the fine-tuned diffusion model, enabling object additions, removals, replacements, and relationship modifications in the scene. The input image is from Â©iStockphoto.