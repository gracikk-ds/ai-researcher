Figure 3. Data synthesis. Step (1): Initiating the dataset synthesis, we first generate captions using LLMs that simulate attribute assignment and spatial reasoning scenarios. Step (2): Leveraging LLMs, we create an image layout based on the caption from Step (1), which encompasses two core elements: instance-level annotations delineated by a set of captioned bounding boxes, and a background prompt. Step (3): We employ the LLM-grounded diffusion model [ 18 ] to generate images based on the layout defined in Step (2), ensuring a singular object distinction between the two resultant images.