Figure 4. Overview. To generate an incremental image update, our algorithm takes as input a user mask and a text prompt. (top) We start by transforming the visible pixels and binary mask into patches, and pass them to a vision transformer (ViT) encoder. We then drop all tokens, except those corresponding to the hole region; this is our global context. (bottom) To generate the missing pixels, we initialize a set of noise patches corresponding to the masked region and pass them through a diffusion transformer model for several denoising iterations, until we obtain denoised patches. Unlike previous works [ 7 , 35 ], which process the entire image, our diffusion transformer only processes the patches required to cover the missing region. We train our encoder and diffusion decoder jointly using a diffusion denoising objective on the missing patches. The generated patches are then blended back into the missing region to produce the final output. Our model operates in a pretrained latent image space [ 42 ], but we illustrate our pipeline with RGB images for simplicity.