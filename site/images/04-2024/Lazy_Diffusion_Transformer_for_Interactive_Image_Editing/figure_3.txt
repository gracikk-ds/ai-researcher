Figure 3. Our diffusion transformer decoder (bottom) reduces synthesis computation using two strategies. First, we compress the image context using a separate encoder (not shown) outside the diffusion loop. Second, we only generate tokens corresponding to the masked region to generate. In contrast, typical diffusion transformers (top) [ 7 , 35 ] maintain tokens for the entire image throughout the diffusion process, to preserve global context. When performing inpainting, such model generates a full-size image, most of which is discarded in order to in-fill the hole region only. Existing convolutional diffusion models for inpainting [ 42 ] suffer from the same drawbacks.