Precisely identifying users’ intentions and producing outputs in the suitable modality, whether with text or images, is essential for Multi-modal Interactive Dialog Systems (MIDS). In this way, the systems can deliver more relevant, informative, and contextually fitting responses. Therefore, we think it’s important to check how well these systems can switch between modes of communication in our benchmark test. We propose to evaluate the Modality Switching accuracy for each turn and focus on image and text modalities, as shown at the left bottom of Fig. 3. When a user inputs an image, it is usually accompanied by text describing the user’s query related to the image. The system’s output typically consists of image and text modalities. For each round, we assess 4 different modality switching scenarios mentioned in Sec. 3.1, to ensure a comprehensive evaluation of the system’s ability to generate the right multi-modal outputs. After inference on the benchmark, we calculate the modality switching accuracy as follows: suppose in the i th round, there are n ij samples belonging to j th modality switching scenario, let c ( k ) ij be the binary variable, such that c ( k ) ij = 1 indicates the model producing the correct output modalities. Then, the Modality Switching Accuracy Acc ij in the i th round for j th scenarios is calculated by