Figure 3. Illustrating the overall framework of our approach: During the multi-layered decomposition stage, given a user’s editing instruction and the source image, we first utilize GPT-4V to perform instruction planning, generating a set of detailed layer-wise editing instructions. Then, we segment the source image into multiple image layers, including the background layer that requires additional inpainting, implemented by a novel key-masking self-attention scheme, and the other object layers of the object to manipulate. For the multi-layered fusion stage, We follow the layers’ orders and layer-wise instructions sequentially to paste them onto the canvas in latent space. We further apply multiple denoising steps to harmonize the fused multi-layered latent representations. Additionally, we perform artifact suppression to improve the background inpainting quality.