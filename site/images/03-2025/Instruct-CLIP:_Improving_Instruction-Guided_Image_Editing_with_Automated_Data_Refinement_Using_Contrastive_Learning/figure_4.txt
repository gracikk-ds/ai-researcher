Figure 4. Training our LD-DINOv2 model. To use I-CLIP as part of the training objective for Stable Diffusion [ 23 ], it needs to handle noisy latent images. Therefore, we replace the original DINOv2 backbone in Fig. 3b with a latent-diffusion version of it we call LD-DINOv2, which takes both the noisy latent image ˜ L k from SD VAE encoding and forward-diffusion (FD) timestep t k . We then train LD-DINOv2 to “ignore” the noise and the latentspace compression and to extract the original DINOv2 features using the training objective L LD-DINO v2 (Eq. 7 ).