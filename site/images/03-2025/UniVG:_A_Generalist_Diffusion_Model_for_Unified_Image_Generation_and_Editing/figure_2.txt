Figure 2. An overview of our UniVG. UniVG contains a text encoder to extract prompt embeddings from the input text and an MM-DiT to perform cross-modal fusion for latent diffusion, where all visual guidance (latent noise, input image, and input mask) are concatenated along the channel dimension as a fix-length sequence for high efficiency. Additionally, an external condition can be injected through embedding replacement to have further control. Hence, a generalist UniVG can support diverse tasks, such as text-to-image, in/outpainting, instructionbased editing, layout-guided generation, and ID-preserving generation. We also consider auxiliary tasks, including depth estimation, pose estimation, and referring segmentation, to enhance its visual scene perception.