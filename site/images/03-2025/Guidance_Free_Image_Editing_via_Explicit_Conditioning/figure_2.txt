Figure 2. Explicit conditioning training: We obtain the mean and variance encoder of the context image via the SD encoder, shown in blue. For the instruction prompt, we use our prompt VAE encoder, shown in yellow, that has the same latent dimension as the SD, i.e., 4 × 64 × 64 . It takes the pooled CLIP embeddings, shown in red, as input and maps them to the corresponding mean and variance. The context and prompt mean and variances are fused to form a Gaussian used for sampling in the diffusion process, as in Eq. 14 . We keep the full 77 CLIP embeddings, shown in purple, as input to the UNet for the sake of consistency with the internalization.